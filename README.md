
#  SAR-to-EO Translation and Cloud & Shadow Segmentation Pipeline

This repository presents a complete Earth Observation (EO) processing pipeline with two stages:

1. **SAR to EO Translation** using CycleGAN  
2. **Cloud & Shadow Segmentation** on EO imagery using U-Net

---

##  Development Rationale & Tech Choices

Earth Observation (EO) data is critical for applications like agriculture, environment monitoring, and land classification. However, Sentinel-2 EO imagery is often obscured by cloud cover, making it unusable. Synthetic Aperture Radar (SAR), like Sentinel-1, is weather-agnostic but difficult to visually interpret.

To solve this:

- We used **CycleGAN** for **unpaired domain translation** â€” ideal for converting SAR to EO without exact matching tiles.
- **EfficientNet-B0** was chosen as the encoder for its lightweight and accurate design, making it suitable for 256Ã—256 tiles on a single GPU.
- A **U-Net** was employed for segmentation due to its encoder-decoder structure and **skip connections**, which are great for capturing fine-grained spatial features like cloud boundaries.
- **TacoReader** helped us work with the CloudSEN12 and Sen12MS datasets using STAC-compliant metadata.
- We used **mixed precision (AMP)** and **gradient clipping** to stabilize training and optimize GPU usage.

---

##  Project Structure

\`\`\`
.
â”œâ”€â”€ Cloud_Mask/
â”‚   â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ Readme.md
â”‚   â”œâ”€â”€ best_model_weights.pth
â”‚   â”œâ”€â”€ cloud_segmentation_readme.docx
â”‚   â”œâ”€â”€ code.ipynb
â”‚   â”œâ”€â”€ final_model_weights.pth
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ SAR_to_EO/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ Readme.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ sar-to-eo-2.ipynb
â”‚
â”œâ”€â”€ .gitattributes
â””â”€â”€ Readme.md
\`\`\`

---

## Part 1: SAR â†’ EO Translation using CycleGAN

###  Objective

Translate Sentinel-1 SAR images into Sentinel-2-like EO images using CycleGAN variants trained on a filtered subset of Sen12MS.

###  EO Target Configurations

- **RGB**: B4 (R), B3 (G), B2 (B)
- **RGB + NIR**: B4, B3, B2, B8
- **NIRâ€“SWIRâ€“RE**: B8 (NIR), B11 (SWIR), B5 (Red Edge)

###  How to Run

\`\`\`bash
pip install torch torchvision rasterio matplotlib scikit-learn pillow torchmetrics
\`\`\`

Then run \`sar-to-eo-2.ipynb\` in order.

---

###  Preprocessing Workflow

- Pair SAR and EO tiles using filename matching
- Read and stack SAR bands: VV, VH, VVâ€“VH, |âˆ‡VV| (Sobel)
- Resize tiles to 256Ã—256
- Normalize using percentile clipping â†’ scale to [-1, 1]
- Cache tensors as \`.pt\` files for fast loading

---

###  Model Architecture

#### CycleGAN with EfficientNet-B0 Backbone

- **Generators (G, F)**:
  - G: SAR (4-band) â†’ EO (3/4-band)
  - F: EO â†’ SAR (4-band)
- **Discriminators**: PatchGAN (70Ã—70)
- **Losses**:
  - \`ð“›_G = ð“›_adv + Î»_cyc ð“›_cyc + Î»_sup ð“›_sup (+ Î»_id ð“›_id)\`
  - \`ð“›_D = MSE(D_real, 0.9) + MSE(D_fake, 0)\`

###  Training Features

- Mixed precision (AMP)
- Gradient clipping (â€–gâ€–â‚‚ â‰¤ 1.0)
- Label smoothing (real = 0.9)
- Checkpointing every 10 epochs

---

###  Results (After 25 Epochs)

#### RGB_NIR
- **PSNR**: 15.92â€“21.89 dB
- **SSIM**: 0.378â€“0.750
- **NDVI MAE**: 0.153

#### NIR_SWIR_RE
- **PSNR**: up to 43.81 dB
- **SSIM**: up to 0.954

#### RGB
- **PSNR**: ~15 dB
- **SSIM**: Low, needs more epochs

---

##  Part 2: Cloud & Shadow Segmentation on EO Images

###  Project Overview

We use a U-Net model to segment EO images into three classes:
- \`0\`: Clear
- \`1\`: Cloud / Thin Cloud
- \`2\`: Shadow

###  Dataset

Filtered CloudSEN12 tiles over Mexico using TacoReader.

### How to Run

\`\`\`bash
pip install torch torchvision rasterio matplotlib scikit-learn geopandas tacoreader
\`\`\`

Prepare dataset:
\`\`\`python
import tacoreader
taco_df = tacoreader.load("mini.taco")
\`\`\`

Train:
\`\`\`bash
python train_unet.py
\`\`\`

---

### Preprocessing Summary

- Selected 9 bands: \`[B2, B3, B4, B5, B6, B7, B8, B11, B12]\`
- Normalized to [0, 1] by dividing by 10000
- Converted 8-class ground truth to 3-class
- Ignored invalid labels (\`255\`)

---

###  U-Net Model Details

- 4 encoder-decoder blocks
- BatchNorm + ReLU activations
- 9 input channels â†’ 3 output classes
- Loss: \`CrossEntropyLoss (ignore_index=255)\`
- Optimizer: \`AdamW\`
- Metrics: Accuracy, F1 (macro), IoU (macro)

---

###  Results

#### Validation (Epoch 35/40)
- **Accuracy**: 0.888
- **F1 (macro)**: 0.837
- **IoU (macro)**: 0.754

#### Test Set
- **Accuracy**: 0.8606
- **F1 (macro)**: 0.7423
- **IoU (macro)**: 0.6527

---

###  Sample Predictions

Stored under \`sample_outputs/\`:
- \`input_.png\` â†’ RGB Input
- \`gt_.png\` â†’ Ground Truth
- \`pred_.png\` â†’ Prediction

---

##  Pipeline Flow

\`\`\`mermaid
graph LR
A[SAR Sentinel-1] --> B[CycleGAN G: SAR â†’ EO]
B --> C[EO (RGB/NIR/SWIR)]
C --> D[U-Net: Cloud & Shadow Segmentation]
D --> E[Cloud Mask Outputs]
\`\`\`

---

##  Tools & Libraries Used

- \`PyTorch\`, \`torchvision\` â€“ DL Framework
- \`TacoReader\` â€“ Dataset filtering & STAC support
- \`Rasterio\` â€“ Read GeoTIFFs
- \`Matplotlib\`, \`Pillow\` â€“ Visualization
- \`scikit-learn\`, \`torchmetrics\` â€“ Evaluation Metrics
- \`AMP\`, \`GradScaler\`, \`Mixed Precision\` â€“ Performance optimization

---

##  Notes

- This modular pipeline allows EO image restoration and segmentation, even under extreme cloud cover.
- CycleGAN + U-Net combination generalizes well across scenes.
- The project is optimized for reproducibility, interpretability, and extensibility.

---

