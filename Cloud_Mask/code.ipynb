{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import geopandas as gpd\nimport pandas as pd\nimport tacoreader\nimport rasterio as rio\nimport matplotlib.pyplot as plt\n\n# 1. Load the taco dataset\n# HINT: Every TACO dataset is a GeoDataFrame if it fullfill stac requirements\ndataset = tacoreader.load(\"tacofoundation:cloudsen12-l1c\")\n# dataset = dataset.to_geodataframe() # From TortillaDataFrame to GeoDataFrame [geopandas]\n\n# 2. Spatial Query [Only California]\nsubset_sp_temporal = dataset[dataset[\"rai:admin0\"] == \"Mexico\"]\n\n# 4. Filter images that contain cloud shadows\nsubset_final = subset_sp_temporal[subset_sp_temporal[\"cloud_shadow_percentage\"] > 0]\nprint(subset_final.plot())\n\n# 5. Create a new TACO file based on the previous filters\ntacoreader.compile(dataframe=subset_final, output=\"mini.taco\", nworkers=4)\n\n# 6. Load your new TACO file\ndataset = tacoreader.load(\"mini.taco\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T09:44:40.219411Z","iopub.execute_input":"2025-07-24T09:44:40.220262Z","iopub.status.idle":"2025-07-24T09:45:11.972766Z","shell.execute_reply.started":"2025-07-24T09:44:40.220212Z","shell.execute_reply":"2025-07-24T09:45:11.972029Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full U-Net pipeline for 9-band Sentinel-2 based cloud & shadow segmentation with checkpoints and stability fixes\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport numpy as np\nimport rasterio\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, jaccard_score\nimport tacoreader\nimport os\n\n# --- Dataset Class ---\nclass CloudSEN129BandDataset(Dataset):\n    def __init__(self, taco_dataset, patch_size=256):\n        self.dataset = taco_dataset\n        self.patch_size = patch_size\n        self.band_indices = [1, 2, 3, 4, 5, 6, 8, 11, 12]  # B2, B3, B4, B5, B6, B7, B8, B11, B12\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        sample = self.dataset.read(idx)\n        eo_path = sample.read(0)\n        label_path = sample.read(1)\n\n        with rasterio.open(eo_path) as eo_src:\n            eo = eo_src.read(self.band_indices, window=rasterio.windows.Window(0, 0, self.patch_size, self.patch_size))\n            eo = np.nan_to_num(eo)\n            eo = np.clip(eo, 0, 10000).astype(np.float32) / 10000.0\n\n        with rasterio.open(label_path) as label_src:\n            label = label_src.read(1, window=rasterio.windows.Window(0, 0, self.patch_size, self.patch_size)).astype(np.int64)\n\n        label_map = np.full_like(label, 255)\n        label_map[label == 0] = 0\n        label_map[np.isin(label, [1, 2])] = 1\n        label_map[label == 3] = 2\n\n        # Skip entirely invalid labels (all 255)\n        if (label_map != 255).sum() == 0:\n            return self.__getitem__((idx + 1) % len(self))\n\n        return torch.from_numpy(eo), torch.from_numpy(label_map)\n\n# --- U-Net Model ---\nclass UNet(nn.Module):\n    def __init__(self, in_channels=9, num_classes=3):\n        super().__init__()\n        def CBR(in_ch, out_ch):\n            return nn.Sequential(\n                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n                nn.BatchNorm2d(out_ch),\n                nn.ReLU(inplace=True)\n            )\n\n        self.enc1 = CBR(in_channels, 64)\n        self.enc2 = CBR(64, 128)\n        self.enc3 = CBR(128, 256)\n        self.enc4 = CBR(256, 512)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.middle = CBR(512, 1024)\n\n        self.up1 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.dec1 = CBR(1024, 512)\n        self.up2 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.dec2 = CBR(512, 256)\n        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec3 = CBR(256, 128)\n        self.up4 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec4 = CBR(128, 64)\n\n        self.out = nn.Conv2d(64, num_classes, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        e4 = self.enc4(self.pool(e3))\n        m = self.middle(self.pool(e4))\n\n        d1 = self.dec1(torch.cat([self.up1(m), e4], dim=1))\n        d2 = self.dec2(torch.cat([self.up2(d1), e3], dim=1))\n        d3 = self.dec3(torch.cat([self.up3(d2), e2], dim=1))\n        d4 = self.dec4(torch.cat([self.up4(d3), e1], dim=1))\n\n        return self.out(d4)\n\n# --- Metrics ---\ndef compute_metrics(preds, labels):\n    preds = preds.flatten()\n    labels = labels.flatten()\n    mask = labels != 255\n    preds = preds[mask]\n    labels = labels[mask]\n    if len(labels) == 0:\n        return {\"accuracy\": 0, \"f1\": 0, \"iou\": 0}\n    return {\n        \"accuracy\": (preds == labels).sum().item() / len(labels),\n        \"f1\": f1_score(labels.cpu(), preds.cpu(), average='macro', zero_division=0),\n        \"iou\": jaccard_score(labels.cpu(), preds.cpu(), average='macro', zero_division=0)\n    }\n\n# --- Training Loop with Checkpoints ---\ndef train_model(model, train_loader, val_loader, device, epochs=10, checkpoint_dir=\"checkpoints\"):\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    criterion = nn.CrossEntropyLoss(ignore_index=255)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    model.to(device)\n    best_iou = 0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for images, masks in train_loader:\n            images, masks = images.to(device), masks.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n\n            if torch.isnan(loss):\n                print(\"âš ï¸ Skipping batch with NaN loss\")\n                continue\n\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n\n        # Validation and checkpoint\n        model.eval()\n        with torch.no_grad():\n            val_metrics = {\"accuracy\": 0, \"f1\": 0, \"iou\": 0}\n            count = 0\n            for images, masks in val_loader:\n                images, masks = images.to(device), masks.to(device)\n                outputs = model(images)\n                preds = outputs.argmax(1)\n                metrics = compute_metrics(preds, masks)\n                for k in val_metrics:\n                    val_metrics[k] += metrics[k]\n                count += 1\n            for k in val_metrics:\n                val_metrics[k] /= max(count, 1)\n            print(f\"Val Acc: {val_metrics['accuracy']:.3f}, F1: {val_metrics['f1']:.3f}, IoU: {val_metrics['iou']:.3f}\")\n\n            if val_metrics['iou'] > best_iou:\n                best_iou = val_metrics['iou']\n                torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pth\"))\n                print(\"âœ… Saved new best model!\")\n\n# --- Visualization ---\ndef visualize_predictions(model, dataloader, device):\n    model.eval()\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(device), masks.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1)\n            for i in range(min(2, images.size(0))):\n                rgb = images[i, [2, 1, 0]].cpu().numpy().transpose(1, 2, 0)  # B4, B3, B2\n                gt = masks[i].cpu().numpy()\n                pred = preds[i].cpu().numpy()\n                fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n                ax[0].imshow(rgb)\n                ax[0].set_title(\"Sentinel-2 RGB\")\n                ax[1].imshow(gt, cmap=\"gray\")\n                ax[1].set_title(\"Ground Truth\")\n                ax[2].imshow(pred, cmap=\"gray\")\n                ax[2].set_title(\"Prediction\")\n                plt.show()\n            break\n\n# --- Run Everything ---\ntaco = tacoreader.load(\"mini.taco\")\ndataset = CloudSEN129BandDataset(taco)\ntrain_len = int(0.7 * len(dataset))\nval_len = int(0.15 * len(dataset))\ntest_len = len(dataset) - train_len - val_len\ntrain_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len])\ntrain_loader = DataLoader(train_set, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=4)\ntest_loader = DataLoader(test_set, batch_size=4)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(in_channels=9, num_classes=3)\n\ntrain_model(model, train_loader, val_loader, device, epochs=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T10:04:10.355359Z","iopub.execute_input":"2025-07-24T10:04:10.355996Z","iopub.status.idle":"2025-07-24T10:40:05.728922Z","shell.execute_reply.started":"2025-07-24T10:04:10.355970Z","shell.execute_reply":"2025-07-24T10:40:05.728251Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef save_metrics_csv(model, dataloader, device, csv_path=\"model_metrics.csv\"):\n    model.eval()\n    all_metrics = {\"accuracy\": 0, \"f1\": 0, \"iou\": 0}\n    count = 0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(device), masks.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1)\n            metrics = compute_metrics(preds, masks)\n            for k in all_metrics:\n                all_metrics[k] += metrics[k]\n            count += 1\n\n    for k in all_metrics:\n        all_metrics[k] /= max(count, 1)\n\n    df = pd.DataFrame([all_metrics])\n    df.to_csv(csv_path, index=False)\n    print(f\"ðŸ“Š Saved metrics to {csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T10:40:55.115468Z","iopub.execute_input":"2025-07-24T10:40:55.116049Z","iopub.status.idle":"2025-07-24T10:40:55.121684Z","shell.execute_reply.started":"2025-07-24T10:40:55.116019Z","shell.execute_reply":"2025-07-24T10:40:55.121092Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save final weights\ntorch.save(model.state_dict(), \"final_model_weights.pth\")\n\n# Optionally copy best checkpoint to user-accessible path\nimport shutil\nshutil.copy(\"checkpoints/best_model.pth\", \"best_model_weights.pth\")\n\nprint(\"ðŸ’¾ Saved model weights: final_model_weights.pth and best_model_weights.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T10:40:58.343338Z","iopub.execute_input":"2025-07-24T10:40:58.343628Z","iopub.status.idle":"2025-07-24T10:40:58.481647Z","shell.execute_reply.started":"2025-07-24T10:40:58.343606Z","shell.execute_reply":"2025-07-24T10:40:58.481063Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.utils import save_image\nimport os\n\ndef save_sample_predictions(model, dataloader, device, save_dir=\"sample_outputs\", num_samples=20):\n    os.makedirs(save_dir, exist_ok=True)\n    model.eval()\n    count = 0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(1)\n\n            for i in range(images.size(0)):\n                rgb = images[i, [2, 1, 0]].cpu()\n                pred = preds[i].cpu().unsqueeze(0)\n                gt = masks[i].cpu().unsqueeze(0)\n\n                save_image(rgb, os.path.join(save_dir, f\"input_{count}.png\"))\n                save_image(pred / 2.0, os.path.join(save_dir, f\"pred_{count}.png\"))\n                save_image(gt / 2.0, os.path.join(save_dir, f\"gt_{count}.png\"))\n\n                count += 1\n                if count >= num_samples:\n                    print(f\"ðŸ“¸ Saved {num_samples} prediction samples to {save_dir}\")\n                    return\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T10:41:05.741583Z","iopub.execute_input":"2025-07-24T10:41:05.742256Z","iopub.status.idle":"2025-07-24T10:41:06.391779Z","shell.execute_reply.started":"2025-07-24T10:41:05.742233Z","shell.execute_reply":"2025-07-24T10:41:06.391240Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_metrics_csv(model, test_loader, device)\nsave_sample_predictions(model, test_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T10:44:49.797657Z","iopub.execute_input":"2025-07-24T10:44:49.798378Z","iopub.status.idle":"2025-07-24T10:45:00.860092Z","shell.execute_reply.started":"2025-07-24T10:44:49.798354Z","shell.execute_reply":"2025-07-24T10:45:00.859406Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model before evaluating test metrics\nmodel.load_state_dict(torch.load(\"checkpoints/best_model.pth\"))\nmodel.to(device)\n\n# Then run metrics or visualize_predictions\nsave_metrics_csv(model, test_loader, device)  # e.g., saves model_metrics.csv\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}